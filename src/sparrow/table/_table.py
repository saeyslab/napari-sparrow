from typing import Dict, Iterable, Tuple

import numpy as np
import spatialdata
from anndata import AnnData
from spatialdata import SpatialData

from sparrow.shape._shape import _filter_shapes_layer
from sparrow.table._manager import TableLayerManager
from sparrow.utils._keys import _CELLSIZE_KEY, _INSTANCE_KEY, _REGION_KEY
from sparrow.utils.pylogger import get_pylogger

log = get_pylogger(__name__)


class ProcessTable:
    def __init__(
        self,
        sdata: SpatialData,
        table_layer: str,
        labels_layer: str | Iterable[str] | None = None,
    ):
        """
        Base class for implementation of processing on tables.

        Parameters
        ----------
        spatial_data: SpatialData
            The SpatialData object containing spatial data.
        table_layer: str
            The table layer to use.
        labels_layer : str or Iterable[str] or None
            The label layer(s) to use.
        """
        if sdata.tables == {}:
            raise ValueError(
                "Provided SpatialData object 'sdata' does not contain any 'tables'. "
                "Please create tables via e.g. 'sp.tb.allocation' or 'sp.tb.allocation_intensity' functions."
            )

        if labels_layer is not None:
            if sdata.labels == {}:
                raise ValueError(
                    "Provided SpatialData object 'sdata' does not contain 'labels'. "
                    "Please create a labels layer via e.g. 'sp.im.segment'."
                )
            labels_layer = (
                list(labels_layer)
                if isinstance(labels_layer, Iterable) and not isinstance(labels_layer, str)
                else [labels_layer]
            )

        self.sdata = sdata
        self.labels_layer = labels_layer
        self.table_layer = table_layer
        self._validated_table_layer()
        if self.labels_layer is not None:
            self._validate_layer(layer_list=self.labels_layer)
        if self.labels_layer is None:
            self._validate()

    def _validate_layer(self, layer_list, layer_type="labels"):
        """Generic layer validation helper to reduce code duplication."""
        for _layer in layer_list:
            if _layer not in [*getattr(self.sdata, layer_type)]:
                raise ValueError(f"'{layer_type}' layer '{_layer}' not in 'sdata.{layer_type}'.")
            if _layer not in self.sdata.tables[self.table_layer].obs[_REGION_KEY].cat.categories:
                raise ValueError(
                    f"'{layer_type}' layer '{_layer}' not in 'sdata.tables[\"{self.table_layer}\"].obs[_REGION_KEY].cat.categories'"
                )
            # Check for uniqueness of instance keys
            assert (
                self.sdata.tables[self.table_layer]
                .obs[self.sdata.tables[self.table_layer].obs[_REGION_KEY] == _layer][_INSTANCE_KEY]
                .is_unique
            ), f"'{_INSTANCE_KEY}' is not unique for '{_REGION_KEY}' == '{_layer}'. Please make sure these are unique."

    def _validate(self):
        assert (
            self.sdata.tables[self.table_layer].obs[_INSTANCE_KEY].is_unique
        ), f"'{_INSTANCE_KEY}' is not unique. Please make sure these are unique, or specify a 'labels_layer' via '{_REGION_KEY}'."

    def _validated_table_layer(self):
        """Validate if the specified table layer exists in the SpatialData object."""
        if self.table_layer not in [*self.sdata.tables]:
            raise ValueError(f"table layer '{self.table_layer}' not in 'sdata.tables'.")

    def _get_adata(
        self, index_names_var: Iterable[str] | None = None, index_positions_var: Iterable[int] | None = None
    ) -> AnnData:
        """Preprocess the data by filtering based on the table layer and setting spatialdata attributes."""
        if self.labels_layer is not None:
            adata = self.sdata.tables[self.table_layer][
                self.sdata.tables[self.table_layer].obs[_REGION_KEY].isin(self.labels_layer)
            ]
        else:
            adata = self.sdata.tables[self.table_layer]
        if index_names_var is not None or index_positions_var is not None:
            adata = self._subset_adata_var(
                adata, index_names_var=index_names_var, index_positions_var=index_positions_var
            )
        adata = adata.copy()
        if self.labels_layer is not None:
            adata.uns["spatialdata_attrs"]["region"] = self.labels_layer

        return adata

    @staticmethod
    def _subset_adata_var(
        adata: AnnData, index_names_var: Iterable[str] | None = None, index_positions_var: Iterable[int] | None = None
    ) -> AnnData:
        """
        Subsets AnnData object by index names or index positions of `adata.var`.

        Parameters
        ----------
        adata: AnnData object.
        index_names_var: List of index names to subset. If None, the function will use index_positions.
        index_positions_var: List of integer positions to subset. Used if index_names_var is None.

        Returns
        -------
        - Subsetted AnnData object.
        """
        if index_names_var is not None:
            index_names_var = (
                list(index_names_var)
                if isinstance(index_names_var, Iterable) and not isinstance(index_names_var, str)
                else [index_names_var]
            )
            selected_var = adata.var.loc[index_names_var]
        elif index_positions_var is not None:
            index_names_var = (
                list(index_positions_var) if isinstance(index_positions_var, Iterable) else [index_positions_var]
            )
            selected_var = adata.var.iloc[index_positions_var]
        else:
            raise ValueError("Either index_names or index_positions must be provided.")

        selected_columns = adata.var_names.intersection(selected_var.index)

        adata = adata[:, selected_columns]

        return adata


def correct_marker_genes(
    sdata: SpatialData,
    labels_layer: list[str],
    table_layer: str,
    output_layer: str,
    celltype_correction_dict: Dict[str, Tuple[float, float]],
    overwrite: bool = False,
) -> SpatialData:
    """Returns the updated SpatialData object.

    Corrects celltypes that are higher expessed by dividing them by a value if they exceed a certain threshold.
    The celltype_correction_dict has as keys the celltypes that should be corrected and as values the threshold and the divider.
    """
    process_table_instance = ProcessTable(sdata, labels_layer=labels_layer, table_layer=table_layer)
    adata = process_table_instance._get_adata()
    # Correct for all the genes
    for celltype, values in celltype_correction_dict.items():
        if celltype not in adata.obs.columns:
            log.info(
                f"Cell type '{celltype}' not in obs of AnnData object. Skipping. Please first calculate gene expression for this cell type."
            )
            continue
        adata.obs[celltype] = np.where(
            adata.obs[celltype] > values[0],
            adata.obs[celltype] / values[1],
            adata.obs[celltype],
        )

    sdata = _add_table_layer(
        sdata,
        adata=adata,
        output_layer=output_layer,
        region=process_table_instance.labels_layer,
        overwrite=overwrite,
    )

    return sdata


def filter_on_size(
    sdata: SpatialData,
    labels_layer: list[str],
    table_layer: str,
    output_layer: str,
    min_size: int = 100,
    max_size: int = 100000,
    update_shapes_layers=True,
    overwrite: bool = False,
):
    """Returns the updated SpatialData object.

    All cells with a size outside of the min and max size range are removed.
    """
    process_table_instance = ProcessTable(sdata, labels_layer=labels_layer, table_layer=table_layer)
    adata = process_table_instance._get_adata()
    start = adata.shape[0]

    # Filter cells based on size and distance
    # need to do the copy because we pop the spatialdata_attrs in _add_table_layer, otherwise it would not be updated inplace
    adata = adata[adata.obs[_CELLSIZE_KEY] < max_size, :].copy()
    adata = adata[adata.obs[_CELLSIZE_KEY] > min_size, :].copy()

    sdata = _add_table_layer(
        sdata,
        adata=adata,
        output_layer=output_layer,
        region=process_table_instance.labels_layer,
        overwrite=overwrite,
    )

    if update_shapes_layers:
        mask = sdata.tables[output_layer].obs[_REGION_KEY].isin(process_table_instance.labels_layer)
        indexes_to_keep = sdata.tables[output_layer].obs[mask][_INSTANCE_KEY].values.astype(int)
        sdata = _filter_shapes_layer(
            sdata,
            indexes_to_keep=indexes_to_keep,
            prefix_filtered_shapes_layer="filtered_size",
        )

    filtered = start - adata.shape[0]
    log.info(f"{filtered} cells were filtered out based on size.")

    return sdata


def _add_table_layer(
    sdata: SpatialData,
    adata: AnnData,
    output_layer: str,
    region: list[str],  # list of labels_layers , TODO, check what to do with shapes layers
    overwrite: bool = False,
):
    manager = TableLayerManager()
    manager.add_table(
        sdata,
        adata=adata,
        output_layer=output_layer,
        region=region,
        overwrite=overwrite,
    )

    return sdata


def _back_sdata_table_to_zarr(sdata: SpatialData):
    adata = sdata.table.copy()
    del sdata.table
    sdata.table = spatialdata.models.TableModel.parse(adata)
